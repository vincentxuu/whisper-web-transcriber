import streamlit as st
import whisper
import tempfile
import os
import time
from pathlib import Path
import traceback

# è¨­å®šé é¢é…ç½®
st.set_page_config(
    page_title="èªéŸ³è½‰æ–‡å­—å·¥å…·",
    page_icon="ğŸ¤",
    layout="wide"
)

# ===== æ‰€æœ‰å‡½æ•¸å®šç¾© =====

@st.cache_resource
def load_whisper_model(model_size):
    """è¼‰å…¥ä¸¦å¿«å– Whisper æ¨¡å‹"""
    try:
        model = whisper.load_model(model_size)
        return model
    except Exception as e:
        st.error(f"æ¨¡å‹è¼‰å…¥å¤±æ•—: {str(e)}")
        if "Connection" in str(e) or "URLError" in str(e):
            st.warning("ç¶²è·¯é€£ç·šå•é¡Œï¼Œè«‹æª¢æŸ¥ç¶²è·¯å¾Œé‡è©¦")
        return None

def estimate_processing_time(file_size_mb):
    """ä¼°ç®—è™•ç†æ™‚é–“ï¼ˆåˆ†é˜ï¼‰"""
    # ç°¡å–®ä¼°ç®—ï¼šæ¯ 10MB ç´„ 1 åˆ†é˜
    return max(0.5, file_size_mb / 10)

def format_time(seconds):
    """æ ¼å¼åŒ–æ™‚é–“"""
    if seconds < 60:
        return f"{int(seconds)}ç§’"
    else:
        minutes = int(seconds / 60)
        seconds = int(seconds % 60)
        return f"{minutes}åˆ†{seconds}ç§’"

def format_timestamp(seconds):
    """æ ¼å¼åŒ–æ™‚é–“æˆ³è¨˜ç‚º MM:SS"""
    minutes = int(seconds // 60)
    seconds = int(seconds % 60)
    return f"{minutes:02d}:{seconds:02d}"

def process_audio(uploaded_file, model_size, language, include_timestamps):
    """è™•ç†éŸ³é »æª”æ¡ˆ"""
    # é¡¯ç¤ºé€²åº¦
    progress_bar = st.progress(0)
    status_text = st.empty()
    
    try:
        # æ­¥é©Ÿ1: å„²å­˜æª”æ¡ˆ
        status_text.text("æ­£åœ¨å„²å­˜æª”æ¡ˆ...")
        progress_bar.progress(10)
        
        with tempfile.NamedTemporaryFile(delete=False, suffix=Path(uploaded_file.name).suffix) as tmp_file:
            tmp_file.write(uploaded_file.getvalue())
            tmp_file_path = tmp_file.name
        
        # æ­¥é©Ÿ2: è¼‰å…¥æ¨¡å‹
        status_text.text(f"æ­£åœ¨è¼‰å…¥ {model_size} æ¨¡å‹...")
        progress_bar.progress(30)
        
        # æª¢æŸ¥æ˜¯å¦éœ€è¦é‡æ–°è¼‰å…¥æ¨¡å‹
        if (st.session_state.loaded_model is None or 
            st.session_state.loaded_model_size != model_size):
            
            with st.spinner(f"é¦–æ¬¡è¼‰å…¥ {model_size} æ¨¡å‹ï¼Œè«‹ç¨å€™..."):
                model = load_whisper_model(model_size)
                
            if model is not None:
                st.session_state.loaded_model = model
                st.session_state.loaded_model_size = model_size
                st.session_state.model_loaded = True
            else:
                st.error("æ¨¡å‹è¼‰å…¥å¤±æ•—")
                return
        else:
            model = st.session_state.loaded_model
        
        # æ­¥é©Ÿ3: è½‰æ›éŸ³é »
        status_text.text("æ­£åœ¨é€²è¡ŒèªéŸ³è­˜åˆ¥...")
        progress_bar.progress(60)
        
        start_time = time.time()
        
        # åŸ·è¡Œè½‰æ›
        language_param = None if language == "auto" else language
        result = model.transcribe(tmp_file_path, language=language_param)
        
        # æ­¥é©Ÿ4: å®Œæˆ
        processing_time = time.time() - start_time
        progress_bar.progress(100)
        status_text.text(f"è½‰æ›å®Œæˆï¼è€—æ™‚ {format_time(processing_time)}")
        
        # æ›´æ–°çµ±è¨ˆ
        st.session_state.processing_count += 1
        
        # æ¸…ç†æš«å­˜æª”æ¡ˆ
        os.remove(tmp_file_path)
        
        # é¡¯ç¤ºçµæœ
        st.success("âœ… è½‰æ›æˆåŠŸå®Œæˆï¼")
        
        # çµæœå€åŸŸ
        st.header("ğŸ“ è½‰æ›çµæœ")
        
        # é¡¯ç¤ºçµ±è¨ˆ
        col_stat1, col_stat2, col_stat3 = st.columns(3)
        with col_stat1:
            st.metric("å­—æ•¸", len(result['text'].split()))
        with col_stat2:
            st.metric("å­—å…ƒæ•¸", len(result['text']))
        with col_stat3:
            st.metric("è™•ç†æ™‚é–“", format_time(processing_time))
        
        # é¡¯ç¤ºè½‰æ›å…§å®¹
        if include_timestamps and 'segments' in result:
            # æ™‚é–“æˆ³è¨˜æ¨¡å¼
            st.subheader("å«æ™‚é–“æˆ³è¨˜çš„å…§å®¹")
            
            timestamp_text = ""
            for segment in result['segments']:
                start_time = format_timestamp(segment['start'])
                end_time = format_timestamp(segment['end'])
                text_line = f"[{start_time} - {end_time}] {segment['text']}\n"
                timestamp_text += text_line
                st.text(text_line.strip())
            
            # ä¸‹è¼‰æŒ‰éˆ•
            st.download_button(
                label="ğŸ“¥ ä¸‹è¼‰æ™‚é–“æˆ³è¨˜æ–‡å­—æª”",
                data=timestamp_text,
                file_name=f"{Path(uploaded_file.name).stem}_timestamps.txt",
                mime="text/plain"
            )
        else:
            # ç´”æ–‡å­—æ¨¡å¼
            st.subheader("è½‰æ›å…§å®¹")
            st.text_area(
                "è½‰æ›çµæœ",
                result['text'],
                height=300
            )
            
            # ä¸‹è¼‰æŒ‰éˆ•
            st.download_button(
                label="ğŸ“¥ ä¸‹è¼‰æ–‡å­—æª”",
                data=result['text'],
                file_name=f"{Path(uploaded_file.name).stem}_transcript.txt",
                mime="text/plain"
            )
        
    except Exception as e:
        progress_bar.empty()
        status_text.empty()
        st.error(f"è™•ç†æ™‚ç™¼ç”ŸéŒ¯èª¤: {str(e)}")
        
        # é¡¯ç¤ºè©³ç´°éŒ¯èª¤
        with st.expander("æŸ¥çœ‹è©³ç´°éŒ¯èª¤"):
            st.code(traceback.format_exc())
        
        # æ¸…ç†æš«å­˜æª”æ¡ˆ
        if 'tmp_file_path' in locals() and os.path.exists(tmp_file_path):
            os.remove(tmp_file_path)

# ===== ä¸»ç¨‹å¼ UI =====

# åˆå§‹åŒ– session state
if 'model_loaded' not in st.session_state:
    st.session_state.model_loaded = False
    st.session_state.loaded_model_size = None
    st.session_state.loaded_model = None
    st.session_state.processing_count = 0

# æ¨™é¡Œ
st.title("ğŸ¤ èªéŸ³è½‰æ–‡å­—å·¥å…·")
st.markdown("ä½¿ç”¨ OpenAI Whisper æŠ€è¡“ï¼Œç²¾æº–è½‰æ›æ‚¨çš„éŸ³é »å…§å®¹")

# å‰µå»ºå…©æ¬„å¸ƒå±€
col1, col2 = st.columns([3, 1])

with col1:
    # ä¸»è¦åŠŸèƒ½å€
    st.header("ğŸ“ é¸æ“‡æª”æ¡ˆ")
    
    uploaded_file = st.file_uploader(
        "ä¸Šå‚³éŸ³é »æˆ–è¦–é »æª”æ¡ˆ",
        type=['mp3', 'wav', 'm4a', 'flac', 'mp4', 'avi', 'mov', 'mkv', 'webm'],
        help="æ”¯æ´ MP3, WAV, M4A, FLAC, MP4, AVI, MOV, MKV ç­‰æ ¼å¼"
    )
    
    if uploaded_file is not None:
        # é¡¯ç¤ºæª”æ¡ˆè³‡è¨Š
        file_size_mb = uploaded_file.size / 1024 / 1024
        
        # æª”æ¡ˆè³‡è¨Š
        st.info(f"""
        ğŸ“„ **æª”æ¡ˆåç¨±:** {uploaded_file.name}  
        ğŸ’¾ **æª”æ¡ˆå¤§å°:** {file_size_mb:.1f} MB  
        â±ï¸ **é ä¼°è™•ç†æ™‚é–“:** {estimate_processing_time(file_size_mb):.1f} åˆ†é˜
        """)
        
        # è¨­å®šé¸é …
        st.header("âš™ï¸ è½‰æ›è¨­å®š")
        
        col_setting1, col_setting2, col_setting3 = st.columns(3)
        
        with col_setting1:
            model_size = st.selectbox(
                "é¸æ“‡ AI æ¨¡å‹",
                ["tiny", "base", "small", "medium", "large"],
                index=1,
                format_func=lambda x: {
                    "tiny": "Tiny - æœ€å¿«é€Ÿ",
                    "base": "Base - å¹³è¡¡ï¼ˆæ¨è–¦ï¼‰",
                    "small": "Small - è¼ƒæº–ç¢º",
                    "medium": "Medium - å¾ˆæº–ç¢º",
                    "large": "Large - æœ€æº–ç¢º"
                }[x]
            )
        
        with col_setting2:
            language = st.selectbox(
                "é¸æ“‡èªè¨€",
                ["auto", "zh", "en", "ja", "ko"],
                format_func=lambda x: {
                    "auto": "è‡ªå‹•åµæ¸¬",
                    "zh": "ä¸­æ–‡",
                    "en": "è‹±æ–‡",
                    "ja": "æ—¥æ–‡",
                    "ko": "éŸ“æ–‡"
                }[x]
            )
        
        with col_setting3:
            include_timestamps = st.checkbox("åŒ…å«æ™‚é–“æˆ³è¨˜", value=False)
        
        # è½‰æ›æŒ‰éˆ•
        if st.button("ğŸš€ é–‹å§‹è½‰æ›", type="primary", use_container_width=True):
            process_audio(uploaded_file, model_size, language, include_timestamps)

with col2:
    # å´é‚Šè³‡è¨Š
    st.header("ğŸ“Š ç‹€æ…‹")
    
    # æ¨¡å‹ç‹€æ…‹
    if st.session_state.model_loaded:
        st.success(f"âœ… {st.session_state.loaded_model_size.upper()} æ¨¡å‹å·²è¼‰å…¥")
    else:
        st.info("ğŸ’¤ ç­‰å¾…è¼‰å…¥æ¨¡å‹")
    
    # è™•ç†çµ±è¨ˆ
    st.metric("å·²è™•ç†æª”æ¡ˆ", f"{st.session_state.processing_count} å€‹")
    
    # ä½¿ç”¨æç¤º
    st.header("ğŸ’¡ ä½¿ç”¨æç¤º")
    
    st.markdown("""
    **é¸æ“‡æ¨¡å‹ï¼š**
    - ğŸš€ Tiny: æœ€å¿«ï¼Œé©åˆæ¸¬è©¦
    - âš¡ Base: é€Ÿåº¦èˆ‡å“è³ªå¹³è¡¡
    - ğŸ¯ Large: æœ€æº–ç¢ºï¼Œè¼ƒæ…¢
    
    **æœ€ä½³å¯¦è¸ï¼š**
    - éŸ³è³ªè¶Šå¥½ï¼Œçµæœè¶Šæº–ç¢º
    - ä¸­æ–‡å…§å®¹é¸æ“‡ã€Œä¸­æ–‡ã€
    - æ··åˆèªè¨€é¸ã€Œè‡ªå‹•åµæ¸¬ã€
    
    **æ”¯æ´æ ¼å¼ï¼š**
    - éŸ³é »: MP3, WAV, M4A
    - è¦–é »: MP4, MOV, AVI
    """)

# ç°¡å–®èªªæ˜
with st.expander("â„¹ï¸ é—œæ–¼æ­¤å·¥å…·"):
    st.markdown("""
    æ­¤å·¥å…·ä½¿ç”¨ OpenAI çš„ Whisper æ¨¡å‹é€²è¡ŒèªéŸ³è½‰æ–‡å­—ã€‚
    
    **åŠŸèƒ½ç‰¹é»ï¼š**
    - æ”¯æ´å¤šç¨®éŸ³é »å’Œè¦–é »æ ¼å¼
    - æä¾›å¤šç¨®æ¨¡å‹é¸æ“‡
    - æ”¯æ´å¤šèªè¨€è­˜åˆ¥
    - å¯é¸æ™‚é–“æˆ³è¨˜è¼¸å‡º
    
    **æ³¨æ„äº‹é …ï¼š**
    - é¦–æ¬¡ä½¿ç”¨éœ€è¦ä¸‹è¼‰æ¨¡å‹
    - å¤§æª”æ¡ˆè™•ç†æ™‚é–“è¼ƒé•·
    - è«‹ç¢ºä¿ç¶²è·¯é€£ç·šç©©å®š
    """)
